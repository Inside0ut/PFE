{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2324,
     "status": "ok",
     "timestamp": 1654166936942,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "hLtVT3MuP132"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scikitplot as skplt\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 649,
     "status": "ok",
     "timestamp": 1654166939357,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "Y7Wxle6DENLM",
    "outputId": "8c2caea7-7ed5-4e6a-f801-f276ee15b629"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad</th>\n",
       "      <th>moral_appeal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>psd jobs spring launch webinar monday pmpm vir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the aflcio has always fought alongside workers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>your national monuments are on the chopping block</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>join us for a focus group to share your though...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>with president trump nominating a judge with a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19729</th>\n",
       "      <td>what is senator heidi heitkamp hiding watch be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19730</th>\n",
       "      <td>breaking the washington post just reported on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19731</th>\n",
       "      <td>protecting vermont is injured employees contac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>according to the huffington post days after pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19733</th>\n",
       "      <td>hundreds of new petrochemical plants would dum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19734 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      ad  moral_appeal\n",
       "0      psd jobs spring launch webinar monday pmpm vir...             0\n",
       "1      the aflcio has always fought alongside workers...             1\n",
       "2      your national monuments are on the chopping block             0\n",
       "3      join us for a focus group to share your though...             0\n",
       "4      with president trump nominating a judge with a...             1\n",
       "...                                                  ...           ...\n",
       "19729  what is senator heidi heitkamp hiding watch be...             0\n",
       "19730  breaking the washington post just reported on ...             0\n",
       "19731  protecting vermont is injured employees contac...             1\n",
       "19732  according to the huffington post days after pa...             0\n",
       "19733  hundreds of new petrochemical plants would dum...             1\n",
       "\n",
       "[19734 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('data/moral_appeal_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1654166943731,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "ilUI__p5P-tR"
   },
   "outputs": [],
   "source": [
    "# vectorize testing and training data \n",
    "X_train, X_test, y_train, y_test= train_test_split(df['ad'], df['moral_appeal'] , test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2319,
     "status": "ok",
     "timestamp": 1654166947501,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "3GzQqy98d9xx",
    "outputId": "7d25905b-db13-4a32-dba8-f241e4b39ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('prevaccine', 37760), ('<PAD>', 0), 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data tokenization \n",
    "t = tf.keras.preprocessing.text.Tokenizer(oov_token='<UNK>')\n",
    "\n",
    "# fit the tokenizer on the training documents\n",
    "t.fit_on_texts(X_train)\n",
    "t.word_index['<PAD>'] = 0\n",
    "max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), t.word_index['<UNK>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2636,
     "status": "ok",
     "timestamp": 1654166950135,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "6MyoVSt1fVkZ"
   },
   "outputs": [],
   "source": [
    "# create tokenized data sequences to feed to the neural network \n",
    "train_sequences = t.texts_to_sequences(X_train)\n",
    "test_sequences = t.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1654166950655,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "khWmrmG0g0Cg",
    "outputId": "e439fc94-8b2f-4756-f3f7-0f6b4f054171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15787, 1000), (3947, 1000))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "\n",
    "# pad documents to equal length with 0 \n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1654166951088,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "Z5dHWRZPi8YE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "            Attention Layer sourced from : https://github.com/lzfelix/keras_attention/blob/master/attention/layers.py\n",
    "\n",
    "            Implementation based in the work of Yang et al. \"Hierarchical Attention Networks for Document Classification\". \n",
    "            This implementation also allows changing the common tanh activation function used on the attention layer, as Chen\n",
    "            et al. \"A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task\"\n",
    "            point that removing this component can be beneficial to the model. Supports\n",
    "            masking.\n",
    "    \n",
    "            The mathematical formulation of the model is as follows:\n",
    "              ```\n",
    "              u = f(W * h + b),\n",
    "              a_i = softmax(u_i^T * u_s),\n",
    "              v_i = \\sigma_i a_i * h_i.\n",
    "              ```\n",
    "    \n",
    "            # Arguments\n",
    "                  activation: The activation function f used by the layer (see\n",
    "                      [activations](../activations.md)). By default tanh is used, another common\n",
    "                      option is \"linear\".\n",
    "                  use_bias: Boolean, whether the layer uses a bias vector.\n",
    "                  initializer: Initializer for the `kernel` and `context` matrices\n",
    "                      (see [initializers](../initializers.md)).\n",
    "                  return_attention: If True, instead of returning the sequence descriptor, this\n",
    "                      layer will return the computed attention coefficients for each of the\n",
    "                      sequence timesteps. See Output section for details.\n",
    "                  W_regularizer: Regularizer function applied to the `kernel` weights matrix\n",
    "                      (see [regularizer](../regularizers.md)).\n",
    "                  u_regularizer: Regularizer function applied to the `context` weights matrix\n",
    "                      (see [regularizer](../regularizers.md)).\n",
    "                  b_regularizer: Regularizer function applied to the bias vector\n",
    "                      (see [regularizer](../regularizers.md)).\n",
    "                  W_constraint: Constraint function applied to the `kernel` weights matrix\n",
    "                      (see [constraints](../constraints.md)).\n",
    "                  u_constraint: Constraint function applied to the `contextl` weights matrix\n",
    "                      (see [constraints](../constraints.md)).\n",
    "                  b_constraint: Constraint function applied to the bias vector\n",
    "                      (see [constraints](../constraints.md)).\n",
    "          # Input shape\n",
    "                  nD tensor with shape: `(batch_size, ..., timesteps, input_dim)`.\n",
    "                  The most common situation would be a 3D input with shape\n",
    "                  `(batch_size, timesteps, input_dim)`.\n",
    "          # Outuput shape\n",
    "                  The sequence descriptor with shape `(batch_size, ..., timestamps)`. If\n",
    "                  `return_attention` is True, this layer will return the `alpha_i` weights\n",
    "                  for each timestep, and consequently its output shape will be different, namely:\n",
    "                  `(batch_size, ..., timesteps)`. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.supports_masking = True\n",
    "        self.init = tf.keras.initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = tf.keras.regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = tf.keras.regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = tf.keras.constraints.get(W_constraint)\n",
    "        self.b_constraint = tf.keras.constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight( shape= (input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape = (input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "        \n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        # TF backend doesn't support it\n",
    "        # eij = K.dot(x, self.W) \n",
    "        # features_dim = self.W.shape[0]\n",
    "        # step_dim = x._keras_shape[1]\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), \n",
    "                              K.reshape(self.W, (features_dim, 1))),\n",
    "                        (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'step_dim': self.step_dim}\n",
    "        base_config = super(AttentionLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1654166951088,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "B0DPRBWtj2pY"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embedding_dim, max_sequence_length, gru_dim,dropout = 0.2):\n",
    "  '''\n",
    "    Create a Bidirectional GRU used for binary text classification task\n",
    "    Arguments : \n",
    "      vocab_size: vocabulary size \n",
    "      embedding_dim: embedding dimensions for the document vector representation \n",
    "      max_sequence_length: input sequence length for each document \n",
    "      gru_dim: number of neurones in the GRU layers\n",
    "      dropout : dropout rate used for Dropout regularization layers to minimize overfitting\n",
    "\n",
    "    Returns : \n",
    "    A model with the folowing layers:  \n",
    "            - Input layer to instantiate a tensor using the input preprocessed data\n",
    "            - Embedding layer to represent each document with a context vector\n",
    "            - Biderectional GRU (takes into consideration bidrectional context)\n",
    "            - A custom attention layer that takes **all** of the output of the GRU ( not the last hidden state only)\n",
    "            - Dense layer \n",
    "            - Dropout layer to minimize overfitting\n",
    "            - A Dense layer \n",
    "            - Dropout \n",
    "            - An output layer to get the label of the class \n",
    "  '''\n",
    "  model = Sequential([\n",
    "      layers.Input(shape=(max_sequence_length,)),\n",
    "      layers.Embedding(vocab_size, embedding_dim, trainable=True),\n",
    "      layers.Bidirectional(layers.GRU(gru_dim, return_sequences=True)),\n",
    "      AttentionLayer(max_sequence_length),\n",
    "      layers.Dense(gru_dim*2, activation='relu'),\n",
    "      layers.Dropout( rate = dropout ),\n",
    "      layers.Dense(gru_dim, activation='relu'),\n",
    "      layers.Dropout( rate = dropout ),\n",
    "      layers.Dense(1, activation='sigmoid')              \n",
    "  ])\n",
    "  model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5002,
     "status": "ok",
     "timestamp": 1654166958870,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "-PYlxK2wjDdI",
    "outputId": "56df6297-201d-4d45-fec8-af49150e2412"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:48:00.819373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-02 18:48:01.484178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10417 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1000, 128)         4833408   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1000, 256)        198144    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " attention_layer (AttentionL  (None, 256)              1256      \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,131,625\n",
      "Trainable params: 5,131,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 128 # dimension for dense embeddings for each token\n",
    "GRU_DIM = 128 # total LSTM units\n",
    "VOCAB_SIZE = len(t.word_index)\n",
    "\n",
    "# Create the model\n",
    "model = create_model(vocab_size = VOCAB_SIZE, embedding_dim = EMBEDDING_DIM, max_sequence_length = MAX_SEQUENCE_LENGTH, gru_dim = GRU_DIM)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177643,
     "status": "ok",
     "timestamp": 1654167139591,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "E1a2o_x8mQHg",
    "outputId": "40c31566-9f06-4548-e2c1-6e0140461648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:48:08.948799: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 31s 68ms/step - loss: 0.2242 - accuracy: 0.8829 - val_loss: 0.0166 - val_accuracy: 0.9962\n",
      "Epoch 2/5\n",
      "395/395 [==============================] - 26s 67ms/step - loss: 0.0174 - accuracy: 0.9971 - val_loss: 0.0153 - val_accuracy: 0.9972\n",
      "Epoch 3/5\n",
      "395/395 [==============================] - 26s 67ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0337 - val_accuracy: 0.9918\n",
      "Epoch 4/5\n",
      "395/395 [==============================] - 27s 68ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0239 - val_accuracy: 0.9981\n",
      "Epoch 5/5\n",
      "395/395 [==============================] - 27s 67ms/step - loss: 7.5555e-04 - accuracy: 0.9997 - val_loss: 0.0545 - val_accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7effd4178630>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training \n",
    "batch_size = 32\n",
    "model.fit(X_train, y_train, epochs= 5, batch_size=batch_size, \n",
    "          shuffle=True, validation_split=0.2, verbose=1      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 10179,
     "status": "ok",
     "timestamp": 1654167218166,
     "user": {
      "displayName": "NARDJES AMIEUR",
      "userId": "13751943947351102071"
     },
     "user_tz": -120
    },
    "id": "9_UW2uhEm58b",
    "outputId": "9788e730-2b7b-4232-a540-5d3582b53c70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 3s 28ms/step - loss: 0.0453 - accuracy: 0.9959\n",
      "Accuracy: 99.59%\n",
      "124/124 [==============================] - 4s 24ms/step\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "no moral appeal       0.99      1.00      1.00      1934\n",
      "   moral appeal       1.00      1.00      1.00      2013\n",
      "\n",
      "       accuracy                           1.00      3947\n",
      "      macro avg       1.00      1.00      1.00      3947\n",
      "   weighted avg       1.00      1.00      1.00      3947\n",
      "\n",
      "confusion matrix:\n",
      "[[1928    6]\n",
      " [  10 2003]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAEWCAYAAAAHJwCcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeZElEQVR4nO3de7wVdb3/8dcbtigmNwE1uXhXAjMviKWZdjtqknSxxFuSdqyTl66nY9ZDDe1X2fFopf3M0p+GJopWgiL4+1kc05MCYppgKinGRUNQMENF8PP7Y2bjYrv3WjOw1l6zZ7+fPObBmpnvfOez1tr7s78z3/nOKCIwMyuLHs0OwMysnpzUzKxUnNTMrFSc1MysVJzUzKxUnNTMrFSc1ApA0ixJn0tfnyjprjrXv7OkkNRSz3oz7ru3pGmSVkuashn11P1zaQZJd0o6pdlxlFm3SGqSFklaLultFcs+J2lWE8NqV0TcEBH/0tn7lXSCpLmSXpb0bPrL9946VH0ssD0wMCI+tamVNOpzkXR4mvB/02b5u9LlszLWc4Gk62uVi4ijIuK6TQzXMugWSS3VE/jS5laiRKk+N0lfBS4D/hdJAhoO/BQYV4fqdwKeiIh1dairUZ4H3iNpYMWyU4An6rWDMv7cFFZElH4CFgHnAC8A/dNlnwNmVZQ5GJgDrE7/P7hi3Szgu8B9wCvA7kAAXwSeBP4BXAjsBvwP8BJwM9Ar3X4AcDvJL8+L6euhber/XPp6AnBv+vobwMsV0+vAtem6fsDVwLPAUuAioGe6rifwn8AK4CngjDTelnY+m35p3Z+q8vltSZL0lqXTZcCW6brDgSXA14DlaTyfTdd9B1ibxv0ycBpwAXB9Rd07V8aWvv+n0s/0aeDEtp9Lxu/rwvT7+gdwFzCog/fWGv+VwBkVn99S4Dw2/hn5EbA4/X4fBA5Nlx/Z5n0+XOXnpvK7/t/ArRX1/wC4G1Czf2e68tT0ADrlTSZJ7UPAr4GL0mUbkhqwLUmyORloAY5P5wem62cBfwNGpeu3SH8RbwP6pstfS38gdyVJFAuAU9LtBwKfBLYG+gBTgN9WxFf5g77RL29FmWEkCeWodP43wM+AtwHbAbOBz6frvgD8Jd1mW+D3dJzUjgTWtbeuosxE4P50P4NJEveF6brD0+0npp/LR4A1wIB0/QVsnMTazu/cGlv6Xl4C9krXvR0Y1fZzyfh9/RXYE+idzn+/g/d2OElSOxh4IF32EWAmb/3Dd1L6XbaQJPHngK3ae19Vfm4qv+utSVqDE4BDSf4IDe3oe/CUbepuzeHzgLMkDW6z/GjgyYiYFBHrIuJGkqTw0Yoy10bE/HT96+myiyPipYiYDzwK3BURT0XEauBOYD+AiFgZEbdGxJqI+AfJX+/DsgYtqTfwW+BHEXGnpO1JfvG+HBH/jIjlwKXA+HSTTwOXRcTiiHgB+F6V6gcCK6L64eGJwMSIWB4Rz5O0wE6uWP96uv71iJhO0lrZK+v7a+MNYG9JvSPi2fSzbSvL9/V/IuKJiHiFpNW8b7WdRsT/ANtK2gv4DPDLdspcn36X6yLiEpIWbK332d7PTWt9a0g+x/8CrgfOioglNeqzGrpVUouIR0kO/c5ps2pH4Jk2y54BhlTML26nyr9XvH6lnfltACRtLelnkp6R9BJwD9BfUs+MoV8NPB4RP0jndyL5q/+spFWSVpG02rareD+V8bZ9b5VWAoNq9Iy2/XyeSZdtqKNNUlxD+t7ziIh/AseRtDSflXSHpBEZ4mmNqfL7em4T4pkEnAm8n6QlvBFJX5f0WNqTu4qkRT6oRp3t/dxsEBEPkBxuiyT52mbqVkktdT7wr2z8C7CMJFFUGk5yXqXV5tzO5Gskf9EPioi+wPvS5aq1oaRzSA6jTqtYvJjkcHdQRPRPp74RMSpd/yzJoWer4VV28ce0ro9VKdP28xmeLtsU/yQ57Gq1Q+XKiJgZER8mOfT8C/DzDPG0xrS0nbJ5TCI5Tzo9bUVtIOlQknOcnyY5tO5Pcj6v9Tvs6Oej6s+NpDNIWnzL0vptM3W7pBYRC4GbgLMrFk8H9kwva2iRdBwwkqRVVw99SFpuqyRtS5JYa5J0VBrnx9PDqNb38CzJye9LJPWV1EPSbpJaD2lvBs6WNFTSAN7aMqWirtUkh+VXSPpY2qrcQtJRki5Oi90IfFvSYEmD0vI1L1/owJ+A90kaLqkf8M2K97u9pHHppTevkRzGvtFOHQ35viLiaZLTAt9qZ3UfknOHzwMtks4jOZ/a6u/Aznl6OCXtSdLBcxLJYeg3JO27adFbq26X1FITSU5KA8k5L2AsSYtqJclfzLERsaJO+7uM5IT1CpIT7jMybnccyYn5x9Lrx16WdGW67jNAL5IOiReBW0haN5C0bmYCDwPzSDpIOpSeH/oq8G2SX9rFJIdhv02LXATMBR4B/pzWeVHG99B2X/+X5I/KIyQ9iJWJqEcaxzKSnurDgH9rp46GfV8RcW9EtNcKnUnyvT1Bcqj7KhsfWrZeWLxS0rxa+0kP968HfhARD0fEk8C5wCRJW27Oe+juFOGbRJpZeXTXlpqZlZSTmpk1jaRr0iGMj3awXpJ+LGmhpEck7V+rTic1M2uma0kuAO/IUcAe6XQ6ySiMqpzUzKxpIuIekk6hjowDfhmJ+0mu73x7lfJ0+q1oqlFL71CvPs0Ow3LY7x3VLoGzonnmmUWsWLGi5vWR1fTsu1PEuldqFwTilefnk/QUt7oqIq7KsbshbNzLvCRd9mxHGxQrqfXqw5Z7fbrZYVgO9z1webNDsBwOOWj0ZtcR615lyxHjaxcEXn3oJ69GxObvNIdCJTUz6wIEaLMae3ksZePRMUOpMXLE59TMLD/1yDZtvqnAZ9Je0HcDq9MRNR1yS83M8qtTS03SjSS3fxokaQnJEMItACLiSpIhcR8BFpLcmOCztep0UjOznAQ9st5gprqIOL7G+iC5yWlmTmpmlo+o16FlQzipmVlO6syOgtyc1MwsP7fUzKxU3FIzs/KQW2pmViKibr2fjeCkZmY5uaVmZmXTw+fUzKwsfJ2amZWOez/NrDzqN0yqEZzUzCw/H36aWWnIw6TMrGzcUjOzUnFLzczKwxffmlmZeJiUmZWLW2pmVjY+p2ZmpeKWmpmViltqZlYa8jk1MysZ9XBSM7OSECAffppZaSidCspJzcxykltqZlYuTmpmVio93FFgZqXhc2pmVibyOTUzKxsnNTMrFSc1MysVJzUzKw+B/IR2MyuLoncUFPdiEzMrLEmZpgz1HCnpcUkLJZ3Tzvrhkn4v6SFJj0j6SK06ndTMLD9lnKpVIfUErgCOAkYCx0sa2abYt4GbI2I/YDzw01qhOamZWT6qW0ttDLAwIp6KiLXAZGBcmzIB9E1f9wOW1arU59TMLLcc59QGSZpbMX9VRFyVvh4CLK5YtwQ4qM32FwB3SToLeBvwoVo7dFIzs1yE8oz9XBERozdjd8cD10bEJZLeA0yStHdEvNHRBj78NLP86nBODVgKDKuYH5ouq3QacDNARPwR2AoYVK1SJzUzy6d+59TmAHtI2kVSL5KOgKltyvwN+CCApHeQJLXnq1Xqw08zy60e16lFxDpJZwIzgZ7ANRExX9JEYG5ETAW+Bvxc0ldIOg0mRERUq9dJzcxyq9fFtxExHZjeZtl5Fa8XAIfkqdNJzcxyK/IwKZ9Tq5Mrzz+RZ+7+HnOnnNthmUu+cSyP3nY+s2/6JvuOGNqJ0Vl77po5g31G7cWoEbvzw4u//5b1r732GiedcByjRuzOoQcfxDOLFnV+kAWU9Xxas4ZSNTSp1RoCUSaTpt3PuDOu6HD9Ee8dyW7DB7P3uO9w5kU38uNzx3didNbW+vXr+fLZZ3DbtDt56JEFTJl8I48tWLBRmWuvuZoB/Qcw/y8LOetLX+Fb5/5Hk6Itnm6Z1DIOgSiN++b9lRdWr+lw/djD9uFXt88GYPafF9GvT292GNS3w/LWWHNmz2a33XZnl113pVevXnzquPHcPu22jcrcPu02Tjz5FAA+8cljmfW7u6lxjrrb6JZJjWxDILqNHbfrz5LnXtwwv/Tvq9hxu/7NC6ibW7ZsKUOHvnmJ1JAhQ1m6dOlbywxLyrS0tNC3Xz9WrlzZqXEWVn2uU2uIRnYUZBkCgaTTgdMB2GKbBoZjZvXiWw9VERFXRcToiBitlt7NDqdhli1fxdAdBmyYH7J9f5YtX9W8gLq5HXccwpIlb/7NXbp0CUOGDHlrmcVJmXXr1vHS6tUMHDiwU+MsIgl69FCmqRkamdSyDIHoNu747z9zwtgxAIx558689PIrPLfipSZH1X2NPvBAFi58kkVPP83atWuZctNkjh57zEZljh57DDdMug6AX996C4e9/wOFbqF0nmL3fjby8HPDEAiSZDYeOKGB+2uq6743gUMP2INB/bdh4YwLufDK6WzR0hOAX9xyLzPunc8R7x3F/Knns+bV1/n8Bdc3OeLuraWlhUt/dDkfPfoI1q9fzykTTmXkqFFMvOA89j9gNGM/egwTTj2NUyeczKgRuzNgwLZMumFys8MujCLndjWyNye9S+VlvDkE4rvVyvfYervYcq9PNyweq78X51ze7BAsh0MOGs2DD87drJS01Q57xk6n/CRT2ScuPvLBzbxLR24NHVHQ3hAIM+viVOyWmodJmVkugqZ1AmThpGZmuTmpmVl5+PDTzMpEFPviWyc1M8up2A8zdlIzs9wKnNOc1MwsJ7mjwMxKxOfUzKx0CpzTnNTMLD+31MysVAqc05zUzCwnuaVmZiUimncDyCyc1MwstwI31JzUzCw/H36aWXl4QLuZlYkvvjWz0nFSM7NSce+nmZWHz6mZWZnI91Mzs7IpcE5zUjOz/HoUOKv1aHYAZta1KL1JZJapdl06UtLjkhZKOqeDMp+WtEDSfEm/qlWnW2pmlls9Oj8l9QSuAD4MLAHmSJoaEQsqyuwBfBM4JCJelLRdzdg2PzQz624kZZpqGAMsjIinImItMBkY16bMvwJXRMSLABGxvFalHbbUJP0EiI7WR8TZtSo3s3LKcUptkKS5FfNXRcRV6eshwOKKdUuAg9psv2eyP90H9AQuiIgZ1XZY7fBzbpV1ZtZNieSyjoxWRMTozdhdC7AHcDgwFLhH0jsjYlW1DdoVEddVzkvaOiLWbEZwZlYSdRpQsBQYVjE/NF1WaQnwQES8Djwt6QmSJDenw9hq7VXSeyQtAP6Szr9L0k9zBm9mZaFsPZ8Zej/nAHtI2kVSL2A8MLVNmd+StNKQNIjkcPSpapVm6Si4DDgCWAkQEQ8D78uwnZmVkEiuU8syVRMR64AzgZnAY8DNETFf0kRJx6TFZgIr04bV74F/j4iV1erNdElHRCxu05OxPst2ZlZO9br2NiKmA9PbLDuv4nUAX02nTLIktcWSDgZC0hbAl0iyqpl1U0Ue+5nl8PMLwBkk3a/LgH3TeTPrhqTsUzPUbKlFxArgxE6Ixcy6iJ5duaUmaVdJ0yQ9L2m5pNsk7doZwZlZMdVpREFDZDn8/BVwM/B2YEdgCnBjI4Mys+JKej+zTc2QJaltHRGTImJdOl0PbNXowMysoDK20prVUqs29nPb9OWd6S1BJpOMBT2ONl2wZta9FPiUWtWOggdJklhr+J+vWBcktwMxs26oyJd0VBv7uUtnBmJmXYOAnl39aVKS9gZGUnEuLSJ+2aigzKzYipvSMiQ1SeeTDCgdSXIu7SjgXsBJzawbkrr+MwqOBT4IPBcRnwXeBfRraFRmVmhdekQB8EpEvCFpnaS+wHI2vgeSmXUzXbKjoMJcSf2Bn5P0iL4M/LGRQZlZsRU4p2Ua+/nF9OWVkmYAfSPikcaGZWZFJalr9n5K2r/auoiY15iQzKzouurh5yVV1gXwgTrHwn7vGM59D1xe72qtgQYceGazQ7AcXnv8b3Wpp8jP1qx28e37OzMQM+saRNdtqZmZtavAp9Sc1MwsH6kEw6TMzCoVOKdluvOtJJ0k6bx0frikMY0PzcyKqsgjCrJ0YvwUeA9wfDr/D+CKhkVkZoVWr+d+NkqWw8+DImJ/SQ8BRMSL6dOUzayb6pKXdFR4XVJPkmvTkDQYeKOhUZlZoRX4io5MSe3HwG+A7SR9l+SuHd9uaFRmVlhddphUq4i4QdKDJLcfEvCxiPAT2s26sQLntEw3iRwOrAGmVS6LiPqMtzCzLqW1o6Coshx+3sGbD2DZCtgFeBwY1cC4zKzACpzTMh1+vrNyPr17xxc7KG5mZdfEBxVnkXtEQUTMk3RQI4Ixs65BBX70SpZzal+tmO0B7A8sa1hEZlZoAloKfKFalpZan4rX60jOsd3amHDMrCvosrceSi+67RMRX++keMys4JLez2ZH0bFqt/NuiYh1kg7pzIDMrOCaOFg9i2pHxrPT//8kaaqkkyV9onXqjODMrJjqNaBd0pGSHpe0UNI5Vcp9UlJIGl2rzizn1LYCVpI8k6D1erUAfp1hWzMrGQE969BRkJ7eugL4MLAEmCNpakQsaFOuD/Al4IEs9VZLatulPZ+P8mYyaxU5YjezUhE96nNJxxhgYUQ8BSBpMjAOWNCm3IXAD4B/z1JptXzbE9gmnfpUvG6dzKwbSh68kvkmkYMkza2YTq+oagiwuGJ+SbrszX0lF/sPi4g7ssZXraX2bERMzFqRmXUT+UYUrIiImufB2t2N1AP4L2BCnu2qJbUC92+YWTPVaUD7UmBYxfzQdFmrPsDewKz0urgdgKmSjomIuR1VWi2pfXDTYzWzsmo9/KyDOcAeknYhSWbjgRNaV0bEamDQhv1Ks4CvV0toUP1hxi9sZsBmVlL1uElkeh3smcBMknP410TEfEkTgbkRMXVT6vUj8swsF1G/ZxRExHRgeptl53VQ9vAsdTqpmVk+6sJjP83M2lPclOakZmY5leF23mZmGyluSnNSM7PcRI8C33vISc3Mcqln72cjOKmZWW7u/TSzUiluSnNSM7O8fJ2amZWJgJ5OamZWJsVNaU5qZrYJCtxQc1Izs3ySSzqKm9Wc1MwsN7fUzKxEhNxSM7OycO+nmZVLwZ/Q7qRmZrk5qZlZqficmpmVRnKTyGZH0TEnNTPLzXe+NbNSKfLhZ5Hv9dbl3DVzBvuM2otRI3bnhxd//y3rX3vtNU464ThGjdidQw8+iGcWLer8IG2DK88/kWfu/h5zp5zbYZlLvnEsj952PrNv+ib7jhjaidEVV+vhZ5apGRqW1CRdI2m5pEcbtY8iWb9+PV8++wxum3YnDz2ygCmTb+SxBQs2KnPtNVczoP8A5v9lIWd96St869z/aFK0BjBp2v2MO+OKDtcf8d6R7DZ8MHuP+w5nXnQjPz53fCdGV2TK/K8ZGtlSuxY4soH1F8qc2bPZbbfd2WXXXenVqxefOm48t0+7baMyt0+7jRNPPgWAT3zyWGb97m4iohnhGnDfvL/ywuo1Ha4fe9g+/Or22QDM/vMi+vXpzQ6D+nZWeMWVXqeWZWqGhiW1iLgHeKFR9RfNsmVLGTp02Ib5IUOGsnTp0reWGZaUaWlpoW+/fqxcubJT47TsdtyuP0uee3HD/NK/r2LH7fo3L6ACUcapGZreUSDpdOB0gGHDhzc5GjOrpejDpJreURARV0XE6IgYPXjQ4GaHs8l23HEIS5Ys3jC/dOkShgwZ8tYyi5My69at46XVqxk4cGCnxmnZLVu+iqE7DNgwP2T7/ixbvqp5ARVJgZtqTU9qZTH6wANZuPBJFj39NGvXrmXKTZM5euwxG5U5euwx3DDpOgB+festHPb+DxT6Xu/d3R3//WdOGDsGgDHv3JmXXn6F51a81OSoiqHIHQVNP/wsi5aWFi790eV89OgjWL9+PadMOJWRo0Yx8YLz2P+A0Yz96DFMOPU0Tp1wMqNG7M6AAdsy6YbJzQ67W7vuexM49IA9GNR/GxbOuJALr5zOFi09AfjFLfcy4975HPHeUcyfej5rXn2dz19wfZMjLo4i/y1Wo3rfJN0IHA4MAv4OnB8RV1fb5oADRsd9D8xtSDzWGAMOPLPZIVgOrz1+M2+sWb5ZKekd79wvfnnbrExlx+zW/8GIGL05+8urYS21iDi+UXWbWZMVuKXmw08zy0Xy2E8zK5nipjT3fprZpqjTJR2SjpT0uKSFks5pZ/1XJS2Q9IikuyXtVKtOJzUzy6k+Yz8l9QSuAI4CRgLHSxrZpthDwOiI2Ae4Bbi4VnROamaWW53Gfo4BFkbEUxGxFpgMjKssEBG/j4jWAbr3AzVvleKkZma5iFxJbZCkuRXT6RVVDQEWV8wvSZd15DTgzlrxuaPAzHLLMVpgRT2uU5N0EjAaOKxWWSc1M8utTld0LAWGVcwPTZe12Zc+BHwLOCwiXqtVqQ8/zSy3OnV+zgH2kLSLpF7AeGDqRvuR9gN+BhwTEcuzxOakZmb5ZM1oNbJaRKwDzgRmAo8BN0fEfEkTJbXeDeKHwDbAFEl/kjS1g+o28OGnmeVWrztwRMR0YHqbZedVvP5Q3jqd1MwsFz/308zKx0nNzMqkyM/9dFIzs9wKfJMOJzUzy6/AOc1Jzcw2QYGzmpOameXim0SaWekUN6U5qZnZpihwVnNSM7OcmvdMzyyc1MwstwKfUnNSM7N8Wm8SWVROamaWmw8/zaxU3FIzs1IpcE5zUjOznLI9KappnNTMbBMUN6s5qZlZLr5JpJmVjg8/zaxUfEmHmZVLcXOak5qZ5VfgnOakZmb5yJd0mFnZqMBZzUnNzHIrbkpzUjOzTVDghpqTmpnl5ZtEmlmJ+H5qZlY6TmpmVio+/DSz8vB1amZWJsKXdJhZ2RQ4qzmpmVluPqdmZqVS5JtE9mh2AGbWBSnjVKsa6UhJj0taKOmcdtZvKemmdP0DknauVaeTmpnlpoz/qtYh9QSuAI4CRgLHSxrZpthpwIsRsTtwKfCDWrE5qZlZLq0jCrJMNYwBFkbEUxGxFpgMjGtTZhxwXfr6FuCDqnGLkEKdU5s378EVvbfQM82OowEGASuaHYTlUtbvbKfNrWDevAdn9t5CgzIW30rS3Ir5qyLiqvT1EGBxxbolwEFttt9QJiLWSVoNDKTKd1OopBYRg5sdQyNImhsRo5sdh2Xn76xjEXFks2OoxoefZtYsS4FhFfND02XtlpHUAvQDVlar1EnNzJplDrCHpF0k9QLGA1PblJkKnJK+Phb4XUREtUoLdfhZYlfVLmIF4++swdJzZGcCM4GewDURMV/SRGBuREwFrgYmSVoIvECS+KpSjaRnZtal+PDTzErFSc3MSsVJrYFqDQGx4pF0jaTlkh5tdiy2aZzUGiTjEBArnmuBQl+HZdU5qTVOliEgVjARcQ9JL5t1UU5qjdPeEJAhTYrFrNtwUjOzUnFSa5wsQ0DMrM6c1BonyxAQM6szJ7UGiYh1QOsQkMeAmyNifnOjslok3Qj8EdhL0hJJpzU7JsvHw6TMrFTcUjOzUnFSM7NScVIzs1JxUjOzUnFSM7NScVLrQiStl/QnSY9KmiJp682o61pJx6avf1FtsL2kwyUdvAn7WCS99alDHS1vU+blnPu6QNLX88Zo5eOk1rW8EhH7RsTewFrgC5Ur0wdT5BYRn4uIBVWKHA7kTmpmzeCk1nX9Adg9bUX9QdJUYIGknpJ+KGmOpEckfR5AicvT+7v9P2C71ookzZI0On19pKR5kh6WdLeknUmS51fSVuKhkgZLujXdxxxJh6TbDpR0l6T5kn4BNR7RnWzzW0kPptuc3mbdpenyuyUNTpftJmlGus0fJI2oy6dppeEHr3RBaYvsKGBGumh/YO+IeDpNDKsj4kBJWwL3SboL2A/Yi+TebtsDC4Br2tQ7GPg58L60rm0j4gVJVwIvR8R/puV+BVwaEfdKGk4yauIdwPnAvRExUdLRQJar8U9N99EbmCPp1ohYCbyN5OEbX5F0Xlr3mSQPRPlCRDwp6SDgp8AHNuFjtJJyUutaekv6U/r6DyRP2jkYmB0RT6fL/wXYp/V8GclzEvcA3gfcGBHrgWWSftdO/e8G7mmtKyI6uq/Yh4CR0oaGWF9J26T7+ES67R2SXszwns6W9PH09bA01pXAG8BN6fLrgV+n+zgYmFKx7y0z7MO6ESe1ruWViNi3ckH6y/3PykXAWRExs025j9Qxjh7AuyPi1XZiyUzS4SQJ8j0RsUbSLGCrDopHut9VbT8Ds0o+p1Y+M4F/k7QFgKQ9Jb0NuAc4Lj3n9nbg/e1sez/wPkm7pNtumy7/B9CnotxdwFmtM5L2TV/eA5yQLjsKGFAj1n7Ai2lCG0HSUmzVg+ThtaR13hsRLwFPS/pUug9JeleNfVg346RWPr8gOV82L314yM9IWuS/AZ5M1/2S5E4UG4mI54HTSQ71HubNw79pwMdbOwqAs4HRaUfEAt7shf0OSVKcT3IY+rcasc4AWiQ9BnyfJKm2+icwJn0PHwAmpstPBE5L45uPb5FubfguHWZWKm6pmVmpOKmZWak4qZlZqTipmVmpOKmZWak4qZlZqTipmVmp/H+XzWqxpq5nfgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# get model predictions \n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "prediction_probs = model.predict(X_test, verbose=1).ravel()\n",
    "predictions = [1 if prob > 0.5 else 0 for prob in prediction_probs]\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, predictions, target_names=['no moral appeal', 'moral appeal']))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_test, predictions , normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1651056575020,
     "user": {
      "displayName": "ASMAA ELFRAIHI",
      "userId": "14661187667036915130"
     },
     "user_tz": -120
    },
    "id": "B5OZOyX7PYUZ",
    "outputId": "3ba64d48-5124-43a5-b74b-fcfe772b65a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad</th>\n",
       "      <th>moral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yearold danylo is not only battling cancer but...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learn how to use the new staffing law to impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we are live with climate activist anuna de wev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>did you miss the t summit relive the daylong e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>friday is north carolinas online voter registr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>you can make a difference this year donate now...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>dear readers\\nrussian nazis do not stop exterm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>education risks becoming the greatest divider ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>shelling killed her mother\\nwithout an urgent ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>i would like it all to end\\nplaton is distraug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ad  moral\n",
       "0    yearold danylo is not only battling cancer but...      1\n",
       "1    learn how to use the new staffing law to impro...      0\n",
       "2    we are live with climate activist anuna de wev...      0\n",
       "3    did you miss the t summit relive the daylong e...      0\n",
       "4    friday is north carolinas online voter registr...      0\n",
       "..                                                 ...    ...\n",
       "195  you can make a difference this year donate now...      1\n",
       "196  dear readers\\nrussian nazis do not stop exterm...      1\n",
       "197  education risks becoming the greatest divider ...      1\n",
       "198  shelling killed her mother\\nwithout an urgent ...      1\n",
       "199  i would like it all to end\\nplaton is distraug...      1\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the test results \n",
    "save = pd.read_csv('data/sample_moral_appeal.csv')\n",
    "save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1651056576261,
     "user": {
      "displayName": "ASMAA ELFRAIHI",
      "userId": "14661187667036915130"
     },
     "user_tz": -120
    },
    "id": "-d1T63Ehi9EE",
    "outputId": "6870ebad-6a21-4067-b361-12befa563a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 26ms/step - loss: 9.3799 - accuracy: 0.6200\n",
      "Accuracy: 62.00%\n",
      "7/7 [==============================] - 0s 24ms/step\n",
      "confusion matrix:\n",
      "[[28 73]\n",
      " [ 3 96]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "no moral appeal       0.90      0.28      0.42       101\n",
      "   moral appeal       0.57      0.97      0.72        99\n",
      "\n",
      "       accuracy                           0.62       200\n",
      "      macro avg       0.74      0.62      0.57       200\n",
      "   weighted avg       0.74      0.62      0.57       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "norm_ = save['ad']\n",
    "test_ = t.texts_to_sequences(norm_)\n",
    "padded_ = tf.keras.preprocessing.sequence.pad_sequences(test_, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "scores = model.evaluate(padded_, save['moral'], verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "val_ = t.texts_to_sequences(norm_)\n",
    "padded_val = tf.keras.preprocessing.sequence.pad_sequences(val_, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "pred_ =  model.predict(padded_val)\n",
    "save['predicted'] = [1 if prob > 0.5 else 0 for prob in pred_]\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(save['moral'], save['predicted']))\n",
    "print()\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(save['moral'], save['predicted'], normalize=True)\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(save['moral'], save['predicted'], target_names=[ 'no moral appeal', 'moral appeal']))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bi-GRU_attention_moral_appeal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
